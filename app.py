import streamlit as st
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import networkx as nx
import matplotlib.pyplot as plt
import json
import os

# –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
DATA_FILE = "chat_memory.json"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
def load_chat_history():
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, "r") as f:
            return json.load(f)
    return []

def save_chat_history(data):
    with open(DATA_FILE, "w") as f:
        json.dump(data, f)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title("ü§ñ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –¥–∏–∞–ª–æ–≥–æ–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å")

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ GPT-2
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("distilgpt2", cache_dir="./cache")
    model = AutoModelForCausalLM.from_pretrained("distilgpt2", cache_dir="./cache")
    return tokenizer, model

tokenizer, model = load_model()

# **–ù–ê–°–¢–†–û–ô–ö–ò –ù–ï–ô–†–û–°–ï–¢–ò**
st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
layers = st.sidebar.text_input("–°–ª–æ–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 10,20,10):", "10,20,10")
layers = list(map(int, layers.split(",")))

# –í—ã–±–æ—Ä —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ (–¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)
activation = st.sidebar.selectbox("–§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:", ["relu", "sigmoid", "tanh"])

# –§—É–Ω–∫—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–µ—Ç–∏
def visualize_nn(layers):
    G = nx.DiGraph()
    
    for i, neurons in enumerate(layers):
        for j in range(neurons):
            G.add_node(f"L{i}_N{j}", layer=i)
        if i > 0:
            for prev in range(layers[i-1]):
                for curr in range(neurons):
                    G.add_edge(f"L{i-1}_N{prev}", f"L{i}_N{curr}")

    pos = nx.multipartite_layout(G, subset_key="layer")
    plt.figure(figsize=(10, 6))
    nx.draw(G, pos, with_labels=False, node_size=300, edge_color='gray')
    plt.title(f"üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {activation})")
    st.pyplot(plt)

# –ö–Ω–æ–ø–∫–∞ "–û–±–Ω–æ–≤–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å"
if st.sidebar.button("–û–±–Ω–æ–≤–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å"):
    visualize_nn(layers)
    st.sidebar.write("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞!")

# **–ß–ê–¢-–ë–û–¢ –° –ò–°–¢–û–†–ò–ï–ô**
st.subheader("üí¨ –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞
chat_history = load_chat_history()

# –ü–æ–ª–µ –≤–≤–æ–¥–∞
question = st.text_input("")

if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å"):
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
    history_text = " ".join([f"Q: {entry['question']} A: {entry['answer']}" for entry in chat_history[-5:]])
    input_text = history_text + " Q: " + question

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    inputs = tokenizer.encode(input_text, return_tensors="pt")
    response_ids = model.generate(inputs, max_length=200, pad_token_id=tokenizer.eos_token_id)
    response = tokenizer.decode(response_ids[:, inputs.shape[-1]:][0], skip_special_tokens=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    chat_history.append({"question": question, "answer": response})
    save_chat_history(chat_history)

    st.write(f"ü§ñ **–û—Ç–≤–µ—Ç:** {response}")

# –í–´–í–û–î–ò–ú –ò–°–¢–û–†–ò–Æ –ß–ê–¢–ê
st.subheader("üìú –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:")
for entry in chat_history[-5:]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
    st.write(f"**Q:** {entry['question']}")
    st.write(f"**A:** {entry['answer']}")
    st.write("---")

# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –°–¢–†–£–ö–¢–£–†–´ –ù–ï–ô–†–û–°–ï–¢–ò
st.subheader("üï∏Ô∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:")
visualize_nn(layers)
